<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>San Francisco Crime Classification (Kaggle competition) using Spark and Logistic Regression by juandes</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>San Francisco Crime Classification (Kaggle competition) using Spark and Logistic Regression</h1>
        <p></p>

        <p class="view"><a href="https://github.com/juandes/SFCrimeClassification-Spark-LogisticRegression">View the Project on GitHub <small>juandes/SFCrimeClassification-Spark-LogisticRegression</small></a></p>


        <ul>
          <li><a href="https://github.com/juandes/SFCrimeClassification-Spark-LogisticRegression/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/juandes/SFCrimeClassification-Spark-LogisticRegression/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/juandes/SFCrimeClassification-Spark-LogisticRegression">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h1>
<a id="san-francisco-crime-classification-kaggle-competition-using-spark-and-logistic-regression" class="anchor" href="#san-francisco-crime-classification-kaggle-competition-using-spark-and-logistic-regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>San Francisco Crime Classification (Kaggle competition) using Spark and Logistic Regression</h1>

<h2>
<a id="overview" class="anchor" href="#overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overview</h2>

<hr>

<p>The "San Francisco Crime Classification" challenge, is a <a href="https://www.kaggle.com">Kaggle</a> competition aimed to predict the category of the crimes that occurred in the city, given the time and location of the incident.</p>

<p>In this post, I explain and outline my second solution to this challenge. This time
using Spark and Python.</p>

<p>Link to the competition: <a href="https://www.kaggle.com/c/sf-crime">San Francisco Crime Classification</a></p>

<h2>
<a id="learning-method" class="anchor" href="#learning-method" aria-hidden="true"><span class="octicon octicon-link"></span></a>Learning method</h2>

<hr>

<p>The algorithm chosen for the implemented solution, is a <a href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression">multinomial logistic regression</a>, a classification model based on regression where the dependent variable (what we want to predict) is categorical (opposite of continuous).</p>

<h2>
<a id="data" class="anchor" href="#data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data</h2>

<hr>

<p>The competition provides two dataset: a train data set and a test dataset. The
train dataset is made of 878049 observations and the test dataset, of 884262
observations.</p>

<p>Both of them contains incidents from January 1, 2003 to May 13, 2015.</p>

<h3>
<a id="data-fields" class="anchor" href="#data-fields" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data fields</h3>

<ul>
<li>Dates : timestamp of the crime incident.</li>
<li>Category: Category of the incident. Also, this is the variable we want to predict.
This variable is available only in the train dataset.</li>
<li>Descript: A short description of the incident. This variable is available only 
in the train dataset.</li>
<li>DayOfWeek: Day of the week where the incident occurred.</li>
<li>PdDistrict: Police Department District</li>
<li>Resolution: Outcome of the incident. This variable is available only in the 
train dataset.</li>
<li>Address: Address of the incident.</li>
<li>X: Longitude</li>
<li>Y: Latitude</li>
</ul>

<h2>
<a id="model-development" class="anchor" href="#model-development" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model development</h2>

<hr>

<h4>
<a id="setting-up-spark" class="anchor" href="#setting-up-spark" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setting up Spark</h4>

<p>The first lines of the script are for setting the configuration of Spark. The <code>setMaster(...)</code> parameter accept the URL of the master. Usually, I check for this URL on the Spark Web UI, available at <code>http://localhost:8080</code>. The second parameter is the name of the app, and the last one is the amount of memory per worker, which I set to 2 GB.</p>

<div class="highlight highlight-python"><pre>conf <span class="pl-k">=</span> SparkConf().setMaster(<span class="pl-s"><span class="pl-pds">"</span>spark://spark.master.url:7077<span class="pl-pds">"</span></span>).setAppName(
    <span class="pl-s"><span class="pl-pds">"</span>SFCrime-Kaggle<span class="pl-pds">"</span></span>). \
    <span class="pl-c1">set</span>(<span class="pl-s"><span class="pl-pds">"</span>spark.executor.memory<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>2g<span class="pl-pds">"</span></span>)
sc <span class="pl-k">=</span> SparkContext(<span class="pl-smi">conf</span><span class="pl-k">=</span>conf)
sqlContext <span class="pl-k">=</span> SQLContext(sc)<span class="pl-c1">4</span>w</pre></div>

<h4>
<a id="loading-data-and-required-packages" class="anchor" href="#loading-data-and-required-packages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading data and required packages</h4>

<p>For loading the train and test dataset (both csv files), I used the package [spark-csv][<a href="http://spark-packages.org/package/databricks/spark-csv">http://spark-packages.org/package/databricks/spark-csv</a>].</p>

<p>To download the package and to add it to the project, use this command <code>$SPARK_HOME/bin/spark-shell --packages com.databricks:spark-csv_2.11:1.2.0-s_2.11</code> when using spark-shell, spark-submit or pyspark.</p>

<p>Now, we load both files, and use <code>registerTempTable</code> on the train dataset, to run SQL statements on it.</p>

<div class="highlight highlight-python"><pre><span class="pl-c"># Import both the train and test dataset and register them as tables</span>
train <span class="pl-k">=</span> sqlContext.read.format(<span class="pl-s"><span class="pl-pds">'</span>com.databricks.spark.csv<span class="pl-pds">'</span></span>).options(
    <span class="pl-smi">header</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>true<span class="pl-pds">'</span></span>) \
    .load(<span class="pl-s"><span class="pl-pds">'</span>train.csv<span class="pl-pds">'</span></span>)
train.registerTempTable(<span class="pl-s"><span class="pl-pds">'</span>train<span class="pl-pds">'</span></span>)

test <span class="pl-k">=</span> sqlContext.read.format(<span class="pl-s"><span class="pl-pds">'</span>com.databricks.spark.csv<span class="pl-pds">'</span></span>).options(
    <span class="pl-smi">header</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>true<span class="pl-pds">'</span></span>) \
    .load(<span class="pl-s"><span class="pl-pds">'</span>test.csv<span class="pl-pds">'</span></span>)</pre></div>

<h4>
<a id="preparing-the-dataset" class="anchor" href="#preparing-the-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Preparing the dataset</h4>

<p>After loading the datasets, my next step was to do some make some modifications on the training dataset and preparing it for the training phase.</p>

<div class="highlight highlight-python"><pre><span class="pl-c"># Get all the unique categories and add them to a dictionary</span>
crimeCategories <span class="pl-k">=</span> sqlContext.sql(
    <span class="pl-s"><span class="pl-pds">'</span><span class="pl-k">SELECT DISTINCT</span> Category <span class="pl-k">FROM</span> train<span class="pl-pds">'</span></span>).collect()
crimeCategories.sort()

categories <span class="pl-k">=</span> {}
<span class="pl-k">for</span> category <span class="pl-k">in</span> crimeCategories:
    categories[category.Category] <span class="pl-k">=</span> <span class="pl-c1">float</span>(<span class="pl-c1">len</span>(categories))</pre></div>

<p>The first step was to get all the unique crime categories and add them to a dictionary, using the category as the key and an integer (the current size of the dictionary as the time of insertion), as a value. So, instead of using the category string as the response (what we want to predict), we are using an integer.
...</p>

<p>Then, I created a <code>HashingTF</code> object which does a similar job do what I did with the dictionary; HashingTF maps a sequence of terms into an integer. We will use this object to convert the vectors of predictors into a vector of numeric values.</p>

<div class="highlight highlight-python"><pre><span class="pl-c"># HashingTF transforms a string into a numerical value  </span>
htf <span class="pl-k">=</span> HashingTF(<span class="pl-c1">5000</span>)</pre></div>

<p>Now, we use Spark's <code>map</code> function to convert every observation of the dataset into a <code>LabeledPoint</code>, an object that contains a label and a vector (either sparse or dense) and that is used for classification in Spark.</p>

<p>The features or predictors that I used for the model are the day of week when the incident occurred, the police district where it occurred and the hour.</p>

<div class="highlight highlight-python"><pre><span class="pl-c"># Create LabeledPoint object</span>
trainingData <span class="pl-k">=</span> train.map(<span class="pl-k">lambda</span> <span class="pl-smi">x</span>: LabeledPoint(categories[x.Category],
                                                htf.transform(
                                                    [x.DayOfWeek, x.PdDistrict,
                                                     datetime.strptime(x.Dates,
                                                                       <span class="pl-s"><span class="pl-pds">'</span><span class="pl-c1">%Y</span>-<span class="pl-c1">%m</span>-<span class="pl-c1">%d</span> <span class="pl-c1">%H</span>:<span class="pl-c1">%M</span>:<span class="pl-c1">%S</span><span class="pl-pds">'</span></span>).hour])))</pre></div>

<h4>
<a id="train-the-model-and-predict" class="anchor" href="#train-the-model-and-predict" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train the model and predict.</h4>

<p>After pre-processing the data, the next step is to train the model.</p>

<div class="highlight highlight-python"><pre><span class="pl-c"># Train the model</span>
logisticRegressionModel <span class="pl-k">=</span> LogisticRegressionWithLBFGS.train(trainingData,
                                                            <span class="pl-smi">iterations</span><span class="pl-k">=</span><span class="pl-c1">100</span>,
                                                            <span class="pl-smi">numClasses</span><span class="pl-k">=</span><span class="pl-c1">39</span>)</pre></div>

<p>Note that this time I didn't checked the training error.</p>

<p>This step is follow by preparing the test dataset in a similar way as the training one.</p>

<div class="highlight highlight-python"><pre><span class="pl-c"># Prepare the testting dataset</span>
testingSet <span class="pl-k">=</span> test.map(<span class="pl-k">lambda</span> <span class="pl-smi">x</span>: htf.transform([x.DayOfWeek, x.PdDistrict,
                                               datetime.strptime(x.Dates,
                                                                 <span class="pl-s"><span class="pl-pds">'</span><span class="pl-c1">%Y</span>-<span class="pl-c1">%m</span>-<span class="pl-c1">%d</span> <span class="pl-c1">%H</span>:<span class="pl-c1">%M</span>:<span class="pl-c1">%S</span><span class="pl-pds">'</span></span>).hour]))</pre></div>

<p>And finally, we predict and save the result.</p>

<div class="highlight highlight-python"><pre><span class="pl-c"># Predict using the day of the week and the police district and hour of crime</span>
predictions <span class="pl-k">=</span> logisticRegressionModel.predict(testingSet)
predictions.saveAsTextFile(<span class="pl-s"><span class="pl-pds">'</span>predictionsSpark<span class="pl-pds">'</span></span>)</pre></div>

<h2>
<a id="conclusion" class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h2>

<hr>

<p>The score received this time, was a bit lower than my first attempt (26.78360 and 26.74064). Before I started working with this algorithm, my original plan was to calculate the predicted probability for each class, However, in Spark, this can be done in a binary classification problem and since in this problem, there are 39 possible outcomes, it wasn't going to work. So, since I had already written most of the code, I decided to continue forward and finish it.</p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/juandes">juandes</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
